import streamlit as st
import cv2
import numpy as np
import mediapipe as mp
from PIL import Image

# åˆå§‹åŒ– MediaPipe äººé«”éª¨æ¶åµæ¸¬
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)

# --- æ ¸å¿ƒé‚è¼¯å€ ---

def enhance_image(image):
    """å½±åƒå¢å¼·ï¼šè‡ªå‹•èª¿æ•´äº®åº¦èˆ‡å°æ¯” (CLAHE)"""
    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    cl = clahe.apply(l)
    limg = cv2.merge((cl, a, b))
    return cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)

def detect_pads_color_based(image):
    """
    æ¨¡æ“¬ AED è²¼ç‰‡åµæ¸¬ (åŸºæ–¼é¡è‰²é–¾å€¼)
    """
    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
    
    # å®šç¾©ç™½/ç°/éŠ€è‰²çš„ç¯„åœ (AED è²¼ç‰‡ç‰¹å¾µ)
    lower_white = np.array([0, 0, 160])
    upper_white = np.array([180, 50, 255])
    
    mask = cv2.inRange(hsv, lower_white, upper_white)
    
    # å½¢æ…‹å­¸è™•ç†ï¼Œå»é™¤é›œè¨Š
    kernel = np.ones((5,5), np.uint8)
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
    
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    detected_pads = []
    img_h, img_w = image.shape[:2]
    
    for cnt in contours:
        area = cv2.contourArea(cnt)
        # éæ¿¾å¤ªå°(é›œè¨Š)æˆ–å¤ªå¤§(èƒŒæ™¯)çš„å€åŸŸ
        if area > (img_h * img_w * 0.02) and area < (img_h * img_w * 0.3):
            x, y, w, h = cv2.boundingRect(cnt)
            center = (x + w//2, y + h//2)
            detected_pads.append({'rect': (x, y, w, h), 'center': center, 'type': 'unknown'})
    
    # ç°¡å–®å€åˆ†å·¦å³è²¼ç‰‡ (æ ¹æ“šç•«é¢ä½ç½®)
    pads_sorted = sorted(detected_pads, key=lambda p: p['center'][0])
    final_pads = {}
    
    if len(pads_sorted) >= 1:
        for p in pads_sorted:
            cx, cy = p['center']
            # ç•«é¢å·¦åŠé‚Šç‚º Sternumï¼Œå³åŠé‚Šç‚º Apex
            if cx < img_w / 2 and cy < img_h * 0.6:
                final_pads['sternum'] = p
            elif cx > img_w / 3 and cy > img_h * 0.4:
                final_pads['apex'] = p
                
    return final_pads

def analyze_placement(image, pads):
    """
    é€²è¡Œä¸­é–“æ¨™æº– (Intermediate Standard) åˆ†æ
    """
    results = pose.process(image)
    h, w, _ = image.shape
    
    feedback = []
    score = 100
    
    if not results.pose_landmarks:
        return image, ["ç„¡æ³•åµæ¸¬åˆ°äººé«”ï¼Œè«‹èª¿æ•´æ‹æ”è§’åº¦"], 0

    landmarks = results.pose_landmarks.landmark
    
    # é—œéµé»åº§æ¨™è½‰æ›
    right_shoulder = (int(landmarks[11].x * w), int(landmarks[11].y * h))
    left_shoulder = (int(landmarks[12].x * w), int(landmarks[12].y * h))
    right_hip = (int(landmarks[23].x * w), int(landmarks[23].y * h))
    left_hip = (int(landmarks[24].x * w), int(landmarks[24].y * h))

    annotated_img = image.copy()
    
    # ç•«å‡ºåƒè€ƒç·š
    cv2.line(annotated_img, left_shoulder, left_hip, (255, 255, 0), 2)

    # --- 1. å³ä¸Šè²¼ç‰‡ (Sternum) ---
    if 'sternum' in pads:
        pad = pads['sternum']
        px, py, pw, ph = pad['rect']
        cx, cy = pad['center']
        
        cv2.rectangle(annotated_img, (px, py), (px+pw, py+ph), (0, 255, 0), 2)
        
        if cy > right_shoulder[1]: 
            feedback.append("âœ… å³ä¸Šè²¼ç‰‡ï¼šä½ç½®æ­£ç¢º")
        else:
            feedback.append("âš ï¸ å³ä¸Šè²¼ç‰‡ï¼šä½ç½®éé«˜ (å£“åˆ°é–éª¨)")
            score -= 10
            cv2.rectangle(annotated_img, (px, py), (px+pw, py+ph), (0, 165, 255), 2)
    else:
        feedback.append("â“ å³ä¸Šè²¼ç‰‡ï¼šæœªåµæ¸¬åˆ°")

    # --- 2. å·¦ä¸‹è²¼ç‰‡ (Apex) ---
    if 'apex' in pads:
        pad = pads['apex']
        px, py, pw, ph = pad['rect']
        cx, cy = pad['center']
        
        body_width_at_pad = left_hip[0] - right_hip[0]
        limit_line_x = left_shoulder[0] - (body_width_at_pad * 0.2)
        
        if cx > limit_line_x: 
            feedback.append("âœ… å·¦ä¸‹è²¼ç‰‡ï¼šä½ç½®åˆæ ¼ (ç¬¦åˆä¸­é–“æ¨™æº–)")
            cv2.rectangle(annotated_img, (px, py), (px+pw, py+ph), (0, 255, 0), 2)
        elif cy > left_hip[1]: 
             feedback.append("âŒ å·¦ä¸‹è²¼ç‰‡ï¼šä½ç½®éŒ¯èª¤ (è²¼åœ¨è…¹éƒ¨)")
             score -= 50
             cv2.rectangle(annotated_img, (px, py), (px+pw, py+ph), (255, 0, 0), 3)
        else:
             feedback.append("âš ï¸ å·¦ä¸‹è²¼ç‰‡ï¼šç¨å«Œé å‰ (å»ºè­°å¾€è…‹ä¸‹ç§»å‹•)")
             score -= 20
             cv2.rectangle(annotated_img, (px, py), (px+pw, py+ph), (0, 255, 255), 2)
             
    else:
        feedback.append("â“ å·¦ä¸‹è²¼ç‰‡ï¼šæœªåµæ¸¬åˆ°")

    return annotated_img, feedback, score

# --- Streamlit ä»‹é¢ ---
st.set_page_config(page_title="AED è²¼ç‰‡ä½ç½®æª¢æ ¸ç³»çµ±", page_icon="âš¡")

st.title("âš¡ AED è²¼ç‰‡ä½ç½®æ™ºæ…§æª¢æ ¸")
st.markdown("""
**è¨­è¨ˆè€…**ï¼šç¦çš„å¤§è…¦ (æ–°åŒ—å¸‚æ¶ˆé˜²å±€é«˜ç´šæ•‘è­·æŠ€è¡“å“¡)
**ç”¨é€”**ï¼šé€é AI å½±åƒè¾¨è­˜ï¼Œåˆ†æ AED è²¼ç‰‡é»è²¼ä½ç½®æ˜¯å¦ç¬¦åˆ AHA æŒ‡å¼•ã€‚
**ç•¶å‰æ¨¡å¼**ï¼šğŸŸ¢ ä¸­é–“æ¨™æº– (å¯¦å‹™æ•™å­¸æ¨¡å¼)
""")

uploaded_file = st.file_uploader("è«‹ä¸Šå‚³ AED è¨“ç·´æˆ–ç¾å ´ç…§ç‰‡", type=["jpg", "png", "jpeg"])

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    img_array = np.array(image)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("åŸå§‹å½±åƒ")
        st.image(image, use_column_width=True)
    
    with st.spinner('æ­£åœ¨åˆ†æè§£å‰–ä½ç½®èˆ‡é›»æµå‘é‡...'):
        enhanced_img = enhance_image(img_array)
        pads = detect_pads_color_based(enhanced_img)
        result_img, feedback_text, final_score = analyze_placement(enhanced_img, pads)
        
        with col2:
            st.subheader("åˆ†æçµæœ")
            st.image(result_img, use_column_width=True)
            
        st.divider()
        st.header(f"æ•´é«”è©•åˆ†ï¼š{final_score} åˆ†")
        
        for item in feedback_text:
            if "âŒ" in item:
                st.error(item)
            elif "âš ï¸" in item:
                st.warning(item)
            else:
                st.success(item)
        
        if final_score < 80:
            st.info("ğŸ’¡ æ•™å®˜å»ºè­°ï¼šå·¦ä¸‹å´è²¼ç‰‡è«‹å‹™å¿…ç¢ºèªã€è…‹ä¸­ç·šã€ä½ç½®ï¼Œé¿å…è²¼æ–¼è…¹éƒ¨è»Ÿçµ„ç¹”ã€‚")